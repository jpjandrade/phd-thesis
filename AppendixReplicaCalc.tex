In this chapter we carry out the calculation for the partition function described in section \ref{sec:rle_statmech} and originally presented in \cite{DeMartinoMarsili04} in details. Although the analytical form for the maximization will not be used in the Applications part of this PhD thesis, we believe it's instructive to the reader that is not familiar with the replica method. The level of detail employed here is not published anywhere, and thus we consider an additional contribution of this thesis.

To solve the maximization problem we need to calculate the following integrals (from equation \eqref{eq:a_14}):

\begin{equation}
    \label{eq:a_app_main}
    \max_x U(x) = \int d\xi dx_0 P(\xi) P(x_0)  \lim_{\beta\to\infty} \log \overbrace{\int dx\, e^{\beta U(x| \xi, x_0)}}^{Z(\beta | \xi, x_0)}
\end{equation}

We also know from \eqref{eq:market_clearing} that $x = x_0 +
\sum_{i=1}^N s_i \xi_i$, so we insert this constraint as an integral in $Z(\beta)$:

\begin{equation}
    \label{eq:a_appZ}
    Z(\beta | \xi, x_0) = \int_0^\infty ds \int_0^\infty dx\, e^{\beta U(x)} \delta\left(x - x_0 - \sum_i s_i \xi_i \right)
\end{equation}

Carrying out the integration in equation \eqref{eq:a_app_main} is
extremely hard, mainly because the log function in the integrand
prevents us to factorize the integrals from the coupling created by
$\xi_i^\mu$ and the market clearing condition. This is a recurrent
problem when calculating the energy for disordered systems in
statistical mechanics, which was solved by a clever and extremely
useful technique to deal with the logarithm function, the so called
\textbf{replica method} \cite{NishimoriBook}, which consists in
writing $\log Z$ as:

\begin{equation}
    \label{eq:a_replica_trick}
    \log Z = \lim_{r\to 0} \frac{Z^r - 1}{r}
\end{equation}

The identity above is still exact, but the clever part of the method
is exchanging the $\lim_{r\to 0}$ term with the rest of the
integrals, treating $r$ like an integer throught the whole
calculation: $Z^r$ is written as a product of independent partition
functions, ie, $Z^r = Z_1 Z_2 \ldots Z_r$, each integrated over their
own dynamical variables $x^a$ and $s^a$, $a = 1, \ldots, r$. These
multiple independent systems are the \emph{replicas} that give the
method its name. This may seem strange at first, but the beauty of the
replica method is that this change of operations (between the limit
and the integrals), though not rigorously proved, works very well.

The general strategy of the full calculation will be as follows: we
exchange the order of integrations and limits until we have

\begin{equation}
    \label{eq:a_app_main}
    \lim_{N\to\infty} \frac{1}{N}\max_x U(x) =
    \lim_{r\to\infty} \frac{1}{N}\lim_{\beta\to\infty} \int d\xi dx_0 P(\xi) P(x_0)
    \frac{Z(\beta | \xi, x_0)^r - 1}{r}
\end{equation}
 
The $\frac{1}{N}$ factor was added to avoid the divergence of $U(x)$
in the limit $N\to\infty$\footnote{The divergence actually comes from
  the limit $M\to\infty$ because $U(x)$ is linear in $M$, but because
  we assume $n = N/M$ fixed, scaling on $N$ is equivalent to scaling
  on $M$}. The term $\int d\xi dx_0 P(\xi) P(x_0)
\frac{Z(\beta | \xi, x_0)^r - 1}{r}$ is the partition function
average over the disorder. Because only $Z(\beta | \xi, x_0)$
depends on $\xi$ and $x_0$, we write it as

    \begin{equation}
      \label{eq:a_2}
      \int d\xi dx_0 P(\xi) P(x_0) \frac{Z(\beta | \xi, x_0)^r - 1}{r}
      = \frac{\langle Z^r \rangle_{\xi, x_0} - 1}{r}
    \end{equation}

Where $\langle \cdot \rangle_{\xi, x_0}$ indicates the average
over the disorder. Arriving at a final expression for the term
$\langle Z^r \rangle_{\xi, x_0}$ is the bulk of the work in
calculating $\max U(x)$, but the goal is to write it in the form

\begin{equation}
  \label{eq:a_3}
  \langle Z^r \rangle_{\xi, x_0} = \int d\theta \, e^{\beta N r h(\theta)},
\end{equation}
where $\theta$ is a vector of order parameters. Because we assume
$N\to \infty$, the integral is dominated by it's maximal value, $\theta^\ast$. We
then take the series expansion around $\theta^\ast$ and keep the first
two terms, ie,

\begin{equation}
  \label{eq:a_4}
  \int d\theta  \, e^{\beta N r h(\theta)}  =  e^{\beta N r
    h(\theta^\ast)} \approx 1 + \beta N r h(\theta^\ast)
\end{equation}

Finally, we plug this approximation into equation \eqref{eq:a_app_main}
to get

\begin{equation}
    \label{eq:a_app_main}
    \lim_{N\to\infty} \frac{1}{N}\max_x U(x) =
    h(\theta^\ast)
\end{equation}

With this strategy in mind, we now begin calculating $\langle Z^r
\rangle_{\xi, x_0}$ proper. Using the replica assumption, we expand
$Z^r$ as

\begin{align}
    \label{eq:a_23}
    Z^r & = \prod_{a=1}^r \int_0^\infty ds^a \int_0^\infty dx^a e^{\beta U(x^r)}
    \delta\left(x^a - x_0 - \sum_i s^a_i \xi_i \right) = \\
   & = \int_0^\infty ds^1 \int_0^\infty dx^1 e^{\beta U(x^1)}
    \delta\left(x^1 - x_0 - \sum_i s^1_i \xi_i \right) \times \\
  \times \ldots \times \\
        &\times \int_0^\infty ds^r \int_0^\infty dx^r e^{\beta U(x^r)}
    \delta\left(x^r - x_0 - \sum_i s^r_i \xi_i \right) \nonumber
\end{align}

Gathering all the terms together:

  \begin{equation}
    \label{eq:a_22}
    Z^r = \int_0^\infty \prod_{a=1}^r d x_a \int_0^\infty 
    \prod_{a=1}^r d s_a e^{\beta \sum_a U(x_a)} \prod_{a=1}^r
    \prod_{\mu=1}^M \delta \left( x_\mu^a - x_0^\mu - \sum_{i=1}^N s_i^a \xi_i^\mu\right)
  \end{equation}


We write explicitely the distributions for $x_0$ and $\xi$:

\begin{equation}
    \label{eq:a_24}
    P(x_0) = \prod_\mu e^{-x_0^\mu}
\end{equation}
and

\begin{equation}
    \label{eq:a_25}
    P(\xi_i) = \frac{1}{P_\xi} \prod_{\mu=1}^M \frac{1}{\sqrt{2\pi M^{-1} \Delta^2}}e^{-\frac{(\xi_i^\mu)^2}{2M^{-1}\Delta^2}}
    \delta\left(\sum_{\mu=1}^M \xi_i^\mu + \epsilon\right),
\end{equation}
where $P_\xi$ is the normalization term given by

\begin{equation}
  \label{eq:a_26}
  P_{\xi_i} = \int_0^\infty \prod_{\mu=1}^M d\xi_i^\mu \frac{1}{\sqrt{2\pi M^{-1}\Delta}}e^{-\frac{(\xi_i^\mu)^2}{2 M^{-1}\Delta}}
    \delta\left(\sum_{\mu=1}^M \xi_i^\mu + \epsilon\right)
\end{equation}

The integral over $x_0$ we can leave to the end because they are
already factored and involve no other terms except the initial
endowments. The integrals over $\xi_i^\mu$, however, are coupled due
to the normalization term. Because the $\delta$ integral is not
feasible due to the couplings, too calculate $P_{\xi_i}$, and throughout
this appendix, we will make use of an important identity for the Dirac
delta function, in which we replace it by it's Fourier transform, ie:

\begin{equation}
  \label{eq:a_27}
  \delta(x) = \frac{1}{2\pi} \int_{-\infty}^\infty dk\, e^{i k x}
\end{equation}

With this identity we are able to integrate all the terms in the normalization term $P_\xi$:

\begin{align}
  \label{eq:a_P_xi}
  P_{\xi_i} & = \int_0^\infty \prod_{\mu=1}^M d\xi_i^\mu
  \frac{1}{\sqrt{2\pi M^{-1}\Delta}}e^{-\frac{(\xi_i^\mu)^2}{2 M^{-1}\Delta}}
  \int_{-\infty}^\infty dk \frac{1}{2\pi} e^{i k (\sum_\mu \xi_i^\mu + \epsilon)} =
  \\ & \int_{-\infty}^\infty dk \frac{1}{2\pi} e^{ik\epsilon} \prod_{\mu=1}^M
  \int_0^\infty d\xi_i^\mu \frac{1}{\sqrt{2\pi
      M^{-1}\Delta}}e^{-\frac{(\xi_i^\mu)^2}{2 M^{-1}\Delta} + i k \xi_i^\mu}
\end{align}

We also use another useful identity to solve the gaussian integral in $\xi_i^\mu$. The integral of $e^{-a x^2 + b x}$ can be easily done if we complete the square:

\begin{equation}
  \label{eq:a_gaussian_integral}
  \int_{-\infty}^\infty dx e^{-ax^2 + bx} = \sqrt{\frac{\pi}{a}} e^{\frac{b^2}{4a}}
\end{equation}

This identity is useful in both directions: sometimes we would like to carry out an integration, and then we go from the left hand side to the right hand side. And sometimes, we would like to linearize a squared term ($b$ in this case), and we go from the right hand side to the left hand side, gaining an integral in the process. We now use it to integrate equation \eqref{eq:a_P_xi}:

\begin{equation}
  \label{eq:a_29}
  P_{\xi_i} = \int_{-\infty}^\infty dk \frac{1}{2\pi} e^{ik\epsilon} 
  e^{-M\frac{M^{-1}\Delta k^2}{2}} = \frac{1}{\sqrt{2\pi\Delta}} e^{-\frac{\epsilon^2}{2\Delta}}
\end{equation}

Going back to $Z^r$:

\begin{align}
    \label{eq:a_30}
    & \int d\xi P(\xi)
  Z^r = \int_{-\infty}^\infty \prod_{\mu=1}^M \prod_{i=1}^N
      \frac{1}{P_{\xi_i}} d\xi_i^\mu \frac{1}{\sqrt{2\pi
      M^{-1}\Delta}}e^{-\frac{(\xi_i^\mu)^2}{2 M^{-1}\Delta}}\, 
    \delta\left(\sum_{\mu=1}^M \xi_i^\mu + \epsilon\right) \times \\ &
    \times \int_0^\infty \prod_{a=1}^r d x_a \int_0^\infty
    \prod_{a=1}^r d s_a e^{\beta \sum_a U(x_a)} \prod_{a=1}^r
    \prod_{\mu=1}^M \delta \left(x_\mu^a - x_0^\mu - \sum_{i=1}^N s_i^a
      \xi_i^\mu \right) \nonumber
\end{align}

We again use the Fourier transform identity for the $\delta$ terms:

\begin{equation}
  \label{eq:a_31}
  \delta\left(\sum_{\mu=1}^M \xi_i^\mu + \epsilon\right) =
  \int_{-\infty}^\infty \frac{1}{2\pi} d\hat{z}_i \, e^{i \hat{z}_i \left(\sum_{\mu=1}^M \xi_i^\mu + \epsilon\right)}
\end{equation}

\begin{equation}
  \label{eq:a_32}
  \delta \left(x_\mu^a - x_0^\mu - \sum_{i=1}^N s_i^a \xi_i^\mu\right) = \int_{-\infty}^\infty \frac{1}{2\pi} d\hat{x}_\mu^a\, e^{i \hat{x}_\mu^a \left(x_\mu^a - x_0^\mu - \sum_{i=1}^N s_i^a \xi_i^\mu\right)}
\end{equation}

Writing only the terms involving $\xi_i^\mu$ from equation
\eqref{eq:a_30}, we take the integral over $d\xi_i^\mu$. For each pair
$i,\mu$ we have

\begin{equation}
  \label{eq:a_34}
  \int_{-\infty}^\infty d\xi_i^\mu \frac{1}{\sqrt{2\pi
      M^{-1}\Delta}}e^{-\frac{(\xi_i^\mu)^2}{2 M^{-1}\Delta}} e^{i
    \hat{z}_i \xi_i^\mu} e^{-\sum_a i \hat{x}_\mu^a s_i^a \xi_i^\mu} =
  e^{-\frac{\Delta}{2M} \left(\hat{z}_i - \sum_a \hat{x}_\mu^a s_i^a\right)^2}
\end{equation}

Again, in the above equation we have used the Gaussian integral
identity of equation \eqref{eq:a_gaussian_integral} and the
normalization term was cancelled.

Plugging the product $\prod_{i,\mu} e^{-\frac{\Delta}{2M} \left(\hat{z}_i
 - \sum_a \hat{x}_\mu^a s_i^a\right)^2}$ back on equation
\eqref{eq:a_30} we end up with:

\begin{align}
  \label{eq:a_33}
  & \int_{-\infty}^\infty \prod_{i=1}^N 
  \frac{1}{2\pi} d\hat{z}_i \int_{-\infty}^\infty \prod_{a=1}^r
  \frac{1}{2\pi} \prod_{\mu=1}^M d\hat{x}_\mu^a \int_0^{\infty} d x^a
  \int_0^\infty ds^a \frac{1}{\left[\frac{1}{\sqrt{2\pi\Delta}}
      e^{-\frac{\epsilon^2}{2\Delta}}\right]^N}  \times \\ 
  & \times \exp\left[\beta \sum_a U(x_a) + i\epsilon\sum_{i=1}^N \hat{z}_i + i\sum_{a=1}^r \sum_{\mu=1}^M
    \hat{x}_\mu^a \left(x_\mu^a - x_0^\mu\right) -
    \frac{\Delta}{2M}\sum_{i=1}^N \sum_{\mu=1}^M\left(\hat{z}_i -
      \sum_{a=1}^r \hat{x}_\mu^a s_i^a \right)^2\right]
\end{align}

We now have hit another wall in integrating these expressions: some of
the variables we are integrating on are coupled via the
$\left(\hat{z}_i - \sum_{a=1}^r \hat{x}_\mu^a s_i^a \right)^2$
term. This means we are not able to integrate over, for example,
$s_i^a$ and $s_i^b$ independently. To get around this, we introduce new variables which allows us to factor the exponential:

\begin{equation}
  \label{eq:a_36}
  \omega_{ab} = \frac{1}{N} \sum_{i=1}^N s_i^a s_i^b \quad \text{and}
  \quad k_a = \frac{1}{N} \sum_{i=1}^N \hat{z}_i s_i^a
\end{equation}

To substitute these terms in the equation above, we multiply it again by a delta term and integrate over it, then replace by its Fourier transform, ie:

\begin{equation}
  \label{eq:a_k}
  1 = \int dk_{a} \delta\left(k_a -
    \frac{1}{N}\sum_{i=1}^N s_i^a\right) = \int dk_a
  d\hat{k}_a \frac{N}{2\pi i} e^{\hat{k}_{a} [N k_a - \sum_i
      s_i^a]}  
\end{equation}

\begin{equation}
  \label{eq:a_37}
  1 = \int d\omega_{ab} \delta\left(\omega_{ab} -
    \sum_{i=1}^N s_i^a s_i^b\right) = \int d\omega_{ab}
  d\hat{\omega}_{ab} \frac{N}{4\pi i} e^{\frac{1}{2}\hat{\omega}_{ab} [N \omega_{ab} - \sum_i
      s_i^a s_i^b]}
\end{equation}


A few extra steps were taken in the above passage: first, we used the identity $\delta(x) = \alpha \delta(\alpha x)$ to write $\delta(k_a - \frac{1}{N} \sum_i s_i^a) = N \delta(N k_a - \sum_i s_i^a)$. This change is useful because both terms are of order $N$ and this will allow us to write $\langle Z^r \rangle_{\xi, x_0}$ in the form of \eqref{eq:a_3}. The second step taken was to carry out a change of variable in the integration, $\hat{k}_a \to i\hat{k}_a$ and $\hat{\omega}_{ab} \to \frac{i}{2} \hat{\omega}_{ab}$.

For simplicity, we will now omit the integration limits when the integral is $\int_{-\infty}^\infty$. Replacing the new variables in \eqref{a_33}:

\begin{align}
  \label{eq:a_33}
 \langle Z^r \rangle_{\xi, x_0} & =  \int d\omega_{ab}
  d\hat{\omega}_{ab} \frac{N}{4\pi i} e^{N \hat{\omega}_{ab}
    \omega_{ab}} e^{ - \hat{\omega}_{ab}\sum_i
      s_i^a s_i^b} \int dk_{a}
  d\hat{k}_{a} \frac{N}{2\pi i} e^{N \hat{k}_{a}
    k_{a}} e^{ - \hat{k}_{a}\sum_i
      s_i^a} \times \nonumber \\ 
    &\times \int \prod_{i=1}^N 
  \frac{1}{2\pi} d\hat{z}_i \int \prod_{a=1}^r
  \frac{1}{2\pi} \prod_{\mu=1}^M d\hat{x}_\mu^a \int_0^{\infty} d x^a
  \int_0^\infty ds^a \frac{1}{\left[\frac{1}{\sqrt{2\pi\Delta}}
      e^{-\frac{\epsilon^2}{2\Delta}}\right]^N}  \times \\ 
  & \times e^{\left[\beta \sum_a U(x_a) + i\epsilon\sum_{i=1}^N \hat{z}_i + i\sum_{a=1}^r \sum_{\mu=1}^M
    \hat{x}_\mu^a \left(x_\mu^a - x_0^\mu\right) -
    \frac{\Delta}{2M} \sum_{\mu=1}^M \left(\sum_i \hat{z}_i - 2N\sum_a
      k_a \hat{x}^a_\mu + N \sum_{a,b} \omega_{ab}\hat{x}_\mu^a
      \hat{x}_\mu^b\right)\right]} \nonumber
\end{align}

The sums over $i$ are now completely factorized, which allows us to replace $\sum_i s_i^a$ by $N s^a$ and again we get the $N$ factor to put in evidence. We write the integral over $\omega, \hat{\omega}, k$ e $\hat{k}$ as

\begin{equation}
  \label{eq:a_38}
  \langle Z^r \rangle_{\xi, x_0} = \int\prod_{a,b=1}^r N
  \frac{d\omega_{ab} d\hat{\omega}_{ab}}{4\pi i} \int \prod_{a=1}^r N
  \frac{dk_{a} d\hat{k}_{a}}{2\pi i} e^{N h(\omega, \hat{\omega}, k, \hat{k})},
\end{equation}
which is what we wanted initially. When we take the limit of $N\to\infty$, the integral will be dominated by the maximum value of $h$, which we divide in three terms, $h = g_1 + g_2 + g_3$:

\begin{equation}
  \label{eq:a_40}
  g_1 = -\sum_{a,b=1}^r  \frac{1}{2} \hat{\omega}_{ab} \omega_{ab} - \sum_{a=1}^r
  \hat{k}_a k_a 
\end{equation}

\begin{equation}
  \label{eq:a_41}
  g_2 = \log \int \frac{d\hat{z}}{2\pi} \int_0^\infty \prod_{a=1}^r
  \exp \left[ \frac{1}{2} \sum_{a,b} \hat{\omega}_{ab} s_a s_b +
    \hat{z} \sum_{a=1}^r \hat{k}_a s_a + i\epsilon \hat{z} -
    \frac{\Delta}{2} \hat{z}^2\right] - \log \frac{1}{\sqrt{2\pi\Delta}}
      e^{-\frac{\epsilon^2}{2\Delta}}
\end{equation}

\begin{equation}
  \label{eq:a_42}
  g_3 = \frac{1}{N} \sum_\mu \log \int \prod_a \frac{d\hat{x}_a}{2\pi}
  \int_0^\infty \prod_a dx^a e^{\beta \sum_a U(x^a) + i \sum_a
    \hat{x}^a(x^a-x_0^\mu) - \frac{n\Delta}{2} \sum_{a,b} \hat{x}^a
    \hat{x}^b \omega_{ab} + n\Delta \sum_a \hat{x}^a k_a }
\end{equation}

To find the maximum of $h$ we must solve the following system of equations

\begin{align}
  \label{eq:a_43}
  \frac{\del h}{\del \omega_{ab}}& = 0, \quad \quad \frac{\del h}{\del
    \hat{\omega}_{ab}} = 0 \nonumber \\     \frac{\del h}{\del
    k_{a}}& = 0, \quad \quad  \frac{\del h}{\del \hat{k}_a}= 0 
\end{align}

These are the saddle points for the replica method. Although we are calculating the maximum value of $U(x)$, the saddle point equations give us important information on how the order parameters relate to each other.

At this point we take another important approximation to these calculations. The $r^2$ order parameters $\omega_{ab}$ are the overlap between two different system replicas, $a$ and $b$, ie, how similar are the $s$ vectors in two independent copies of our economy. Because $U(x)$ is a convex function, we know that the maximum of $U(x)$ exists and is unique. Therefore, we expect every replica to converge to the same equilibrium value of $s^a$ in the limit $\beta \to \infty$, and in this case, we cannot distinguish between $\omega_{ab}$ for any two pairs of replica $a$ and $b$. We assume, then, there are only two possible values for $\omega_{ab}$. Either $a = b$ and $\omega_{aa} = \langle s^2 \rangle = \Omega$, the variance of $s$, or $a \neq b$ and $\omega_{ab} = \omega$, the overlap of two different systems. This is the so called replica symmetric approximation, which is exact in this case because we know there is only one equilibrium in the zero temperature limit.

Writing this explicitely, we have that $\omega_{ab}$ and $k_a$ are given by

\begin{align}
  \label{eq:a_44}
  \omega_{ab} & = \Omega \delta_{ab} + \omega (1 - \delta_{ab})
  \nonumber \\
  \hat{\omega}_{ab} & = \hat{\Omega} \delta_{ab} + \hat{\omega}
  (1-\delta_{ab}) \nonumber \\
  k_a & = k \\
  \hat{k}_a & = \hat{k} \nonumber
\end{align}

Replacing these new values in equations \eqref{eq:a_40} - \eqref{eq:a_42} and taking the limit $r\to 0$ we get

\begin{equation}
  \label{eq:a_46}
  \lim_{r\to 0} \frac{1}{r} g_1 = -\frac{1}{2}\left(\Omega\hat{\Omega}
    - \omega \hat{\omega}\right) - k\hat{k}
\end{equation}

\begin{equation}
  \label{eq:a_47}
  \lim_{r\to 0} \frac{1}{r} g_2 = \int dt \frac{1}{\sqrt{2\pi}}
  e^{-\frac{t^2}{2}} \log \int_0^\infty ds \, e^{\frac{\hat{\Omega} -
      \hat{\omega}}{2} s^2 + \left[t\left(\frac{\hat{k}^2}{\Delta} +
      \hat{\omega}\right)^{\frac{1}{2}} +
    i\hat{k}\frac{\epsilon}{\Delta}\right] s}
\end{equation}

\begin{equation}
  \label{eq:a_47}
  \lim_{r\to 0} \frac{1}{r} g_3 = \int dt \frac{1}{\sqrt{2\pi}}
  e^{-\frac{t^2}{2}} \log \int_0^\infty dx \, e^{\beta U(x) -
    \frac{\left(x-x_0 + \sqrt{n\Delta \omega} t - i n \Delta
        k\right)^2}{2n\Delta(\Omega - \omega)} - \frac{1}{2} \log[2\pi
    n \Delta(\Omega - \omega)]}
\end{equation}

In the equations above, $t$ is a gaussian random variable with zero mean and unit variance, which arises from using the identity \eqref{a_gaussian_integral} to linearize $\left(\sum_a s^a\right)^2$, gaining an integral in the process.

We now have a order parameter vector $\theta = (\Omega, \hat{\Omega}, \omega, \hat{\omega}, k, \hat{k})$ and we wish to find the values $\theta^\ast$ that maximizes $h(\theta)$. However, we have some conditions on this solution, in particular we know that it must be well defined for $\beta \to \infty$. Again, because we know that in this limit all replicas must have the same equilibrium, then it must hold that the overlap between replicas must vanish, ie,

\begin{equation}
  \lim_{\beta\to \infty} \Omega - \omega = \frac{1}{2N} \sum_{i=1}^N \left(s_i^a - s_i^b \right)^2 = 0
\end{equation}

But this would imply that some terms in $g_3$ would diverge in the zero temperature limit, so we have to rescale the order parameters for them to remain finite in this limit. We define the new parameters, which are always finite:

\begin{align}
  \label{eq:a_anzats}
  \chi = n \Delta \beta (\Omega - \omega), \quad \hat{\chi} = -\frac{\hat{\Omega} - \hat{\omega}}{\beta}, \quad \kappa = -in\Delta k, \\
  \hat{\kappa} = \frac{i\hat{k}}{\Delta \beta}, \quad \hat{\gamma} = \frac{\hat{\omega}}{\beta^2}
\end{align}

The function $h$ then becomes

\begin{align}
  \label{eq:a_h}
  h &= \frac{1}{2} \left(\Omega \hat{\chi} - \frac{\hat{\gamma}
      \chi}{n \Delta} \right) - \frac{1}{n} \kappa \hat{\kappa} +
  \frac{1}{\beta} \left\langle \log \int_0^\infty ds \,
  e^{\beta \left[-\frac{\hat{\chi}}{2}s^2 + (t \sqrt{\hat{\gamma} - \Delta
      \hat{\kappa}^2} + \hat{\kappa}\epsilon) s\right]}
\right\rangle_t + \nonumber \\ &+
\frac{1}{n\beta}\left\langle \log \int_0^\infty dx \, e^{\beta \left[ U(x) - \frac{(x - x_0 + \kappa +
      \sqrt{n\Delta\Omega}t)^2}{2\chi}\right]} \right\rangle_{t,x_0}
\end{align}

We then finally take the limit $\beta \to \infty$ and again use the saddle point method to solve the integrals on $x$ and $s$, which means they are dominated by their maximum value, ie 

\begin{align}
  \label{eq:a_48}
  h(\beta \to \infty)& = \left\langle \max_s \left[-\frac{\hat{\chi}}{2}s^2 + (t \sqrt{\hat{\gamma} - \Delta
      \hat{\kappa}^2} + \hat{\kappa}\epsilon) s\right] \right\rangle_t +
  \frac{1}{2} \left(\Omega \hat{\chi} - \frac{\hat{\gamma}
      \chi}{n\Delta}\right) - \frac{1}{n} \kappa \hat{\kappa} + \nonumber\\ &+
  \frac{1}{n} \left\langle \max_x \left[U(x) - \frac{(x - x_0 + \kappa +
      \sqrt{n\Delta\Omega}t)^2}{2\chi}\right] \right\rangle_{t,x_o}
\end{align}

Replacing in equation \eqref{eq:a_48} the variables $x$ and $s$ by their maximum values $x^\ast$ and $s^\ast$ and taking the derivatives on the order parameters we finally have the saddle point equations for $h(\theta)$:

\begin{align}
  \frac{\del h}{\del \Omega} & = \frac{\hat{\chi}}{2} -
  \frac{1}{2\chi} \sqrt{\frac{\Delta}{n\Omega}}\left\langle (x^* - x_0
  + \kappa + t \sqrt{n\Delta\Omega})t\right \rangle_{t,x_0} = 0   \label{eq:a_omega}\\
  \frac{\del h}{\del \kappa} & = -\frac{1}{n}\hat{\kappa} -
  \frac{1}{n\chi}\left\langle x^* - x_0 + \kappa +
    t\sqrt{n\Delta\Omega} \right \rangle_{t,x_0} = 0  \label{eq:a_kappa} \\
  \frac{\del h}{\del \hat{\kappa}} & = -\frac{\Delta\hat{\kappa}}{\sqrt{\hat{\gamma} - \Delta
      \hat{\kappa}^2}} \left\langle t s^*\right\rangle_t + \epsilon
  \left\langle s^*\right\rangle_t - \frac{\kappa}{n} = 0 \label{eq:a_hatkappa}\\
  \frac{\del h}{\del \hat{\gamma}} & = \frac{1}{2\sqrt{\hat{\gamma} - \Delta
      \hat{\kappa}^2}} \left\langle t s^*\right\rangle_t -
  \frac{\chi}{2n\Delta} = 0\label{eq:a_gamma}\\
  \frac{\del h}{\del \chi} & = - \frac{\hat{\gamma}}{2n\Delta} + \frac{\left\langle (x^* - x_0 + \kappa +
    t\sqrt{n\Delta\Omega})^2 \right \rangle_{t,x_0}}{2n\chi^2} = 0\label{eq:a_chi}\\
  \frac{\del h}{\del \hat{\chi}} & = -\frac{1}{2} \left\langle (s^*)^2
  \right\rangle_t + \frac{1}{2} \Omega = 0\label{eq:a_hatchi}
\end{align}

We can find $x^\ast$ by solving $\frac{\del}{\del x} \left[U(x) - \frac{(x - x_0 + \kappa + \sqrt{n\Delta\Omega}t)^2}{2\chi}\right] = 0$, resulting in the implicit equation

\begin{equation}
  \label{eq:a_55}
  x^* = x : U'(x^*) = \frac{(x - x_0 + \kappa +
      \sqrt{n\Delta\Omega}t)}{\chi}
\end{equation}

We can replace this in the equations \eqref{eq:a_omega} - \eqref{eq:a_hatchi} to obtain some useful relations. The equation \eqref{eq:a_kappa} becomes, for $x = x^*$

\begin{equation}
  \label{eq:a_56}
  \hat{\kappa} = -\left \langle U'(x^*) \right \rangle_{t,x_0}
\end{equation}

This allows us to identify $\hat{\kappa} = -p$ due to the price equation derived from the first order conditions of the consumer's maximization problems (equation \eqref{eq:p}). Equation \eqref{eq:a_hatchi} allows us to write

\begin{equation}
  \label{eq:a_57}
\Omega = \left\langle (s^*)^2 \right\rangle_t
\end{equation}

The remaining parameters are found through simple algebraic manipulations. With $\Omega$ and $p$ defined, one immediately obtains $\hat{\chi}$

\begin{equation}
  \label{eq:a_58}
\hat{\chi} = \sqrt{\frac{\Delta}{n\Omega}} \left \langle U'(x^*) t
\right \rangle_{t,x_0}
\end{equation}

And from \eqref{eq:a_chi} we have

 \begin{equation}
  \label{eq:a_59}
\hat{\gamma} =
\Delta \left \langle U'(x^*)^2 \right \rangle_{t,x_0}
\end{equation}

With that, $U'(x)$ variance is written as

\begin{equation}
  \label{eq:a_60}
\sigma = \sqrt{\hat{\gamma} - \Delta \hat{\kappa}^2} = \sqrt{\Delta
    \left(\left \langle U'(x^*)^2 \right \rangle_{t,x_0} - \left
        \langle U'(x^*) \right \rangle_{t,x_0}^2 \right)}
\end{equation}

Finally, we have $\chi$ via equation \eqref{eq:a_gamma}

  \begin{equation}
    \label{eq:a_61}
    \chi = \frac{n\Delta}{\sigma} \left \langle t s^* \right \rangle_t
  \end{equation}

And $\kappa$ via equation \eqref{eq:a_hatkappa}

\begin{equation}
  \label{eq:a_62}
  \kappa = p \chi + n\epsilon \left \langle s^* \right \rangle_t
\end{equation}

Thus we have now arrived at equations \eqref{eq:saddlep} - \eqref{eq:saddlekappa}.